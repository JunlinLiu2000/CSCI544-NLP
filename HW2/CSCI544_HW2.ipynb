{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnK6vfq4eUAi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 925
    },
    "id": "3BlC3nclf26c",
    "outputId": "f41f16d9-bc2d-4f4c-dfb0-80838aa013df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2bd24ecb-d751-4afc-b00f-1c09ffcee8f0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>50423057</td>\n",
       "      <td>R135Q3VZ4DQN5N</td>\n",
       "      <td>B00JWXFDMG</td>\n",
       "      <td>657335467</td>\n",
       "      <td>Everbling Purple and Clear Briolette Drop Swar...</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Beauties!</td>\n",
       "      <td>so beautiful even tho clearly not high end ......</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>11262325</td>\n",
       "      <td>R2N0QQ6R4T7YRY</td>\n",
       "      <td>B00W5T1H9W</td>\n",
       "      <td>26030170</td>\n",
       "      <td>925 Sterling Silver Finish 6ct Simulated Diamo...</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Great product.</td>\n",
       "      <td>Great product.. I got this set for my mother, ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>27541121</td>\n",
       "      <td>R3N5JE5Y4T6W5M</td>\n",
       "      <td>B00M2L6KFY</td>\n",
       "      <td>697845240</td>\n",
       "      <td>Sterling Silver Circle \"Friends Forever\" Infin...</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Exactly as pictured and my daughter's friend l...</td>\n",
       "      <td>Exactly as pictured and my daughter's friend l...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>5350721</td>\n",
       "      <td>R2I150CX5IVY9Q</td>\n",
       "      <td>B0006SW2WU</td>\n",
       "      <td>569859289</td>\n",
       "      <td>Surgical Stainless Steel Domed 9mm Fishbone Ri...</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Love it. Fits great. Super comfortable and nea...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>24484424</td>\n",
       "      <td>R1RM9ICOOA9MQ3</td>\n",
       "      <td>B009YPDW70</td>\n",
       "      <td>332947422</td>\n",
       "      <td>Sterling Silver Family Pendant Necklace, 18\"</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>... a Mother's Day gift for my Mom and she lov...</td>\n",
       "      <td>Got this as a Mother's Day gift for my Mom and...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042230</th>\n",
       "      <td>US</td>\n",
       "      <td>52895472</td>\n",
       "      <td>RVR5HEPUCU2C0</td>\n",
       "      <td>B00005RE3U</td>\n",
       "      <td>587330987</td>\n",
       "      <td>Sterling Silver Toggle Bracelet, Round Charm</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nice bracelet</td>\n",
       "      <td>It is nice looking and everything (it is sterl...</td>\n",
       "      <td>2001-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042231</th>\n",
       "      <td>US</td>\n",
       "      <td>40225563</td>\n",
       "      <td>R7FC4HLPYQCBV</td>\n",
       "      <td>B00005OTBA</td>\n",
       "      <td>945322302</td>\n",
       "      <td>10K Yellow Gold &amp;#46;01 ct&amp;#46; Diamond Heart ...</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>beautiful heart for everyday wear</td>\n",
       "      <td>my boyfriend bought me this last christmas, an...</td>\n",
       "      <td>2001-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042232</th>\n",
       "      <td>US</td>\n",
       "      <td>51016122</td>\n",
       "      <td>R1UD30PTI793U2</td>\n",
       "      <td>0930948246</td>\n",
       "      <td>698292720</td>\n",
       "      <td>Country &amp; Blues Harmonica for the Absolute Beg...</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Great for the Absolute Beginner</td>\n",
       "      <td>This is a great way to quickly start learning ...</td>\n",
       "      <td>2001-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042233</th>\n",
       "      <td>US</td>\n",
       "      <td>43629114</td>\n",
       "      <td>R1DXZZ4QSXZLTP</td>\n",
       "      <td>B00005OTAJ</td>\n",
       "      <td>274507819</td>\n",
       "      <td>14K Gold Diamond Cut Etched Hoop Earrings</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Dazzling</td>\n",
       "      <td>the 14kt gold earrings look remarkable...would...</td>\n",
       "      <td>2001-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042234</th>\n",
       "      <td>US</td>\n",
       "      <td>51769631</td>\n",
       "      <td>RV2EZ4SCOCQC2</td>\n",
       "      <td>B00005OTAD</td>\n",
       "      <td>249706161</td>\n",
       "      <td>Floating Heart Pendant Necklace</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Touching Heart</td>\n",
       "      <td>It will be a gift to my special friend. We kno...</td>\n",
       "      <td>2001-11-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3042235 rows × 15 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bd24ecb-d751-4afc-b00f-1c09ffcee8f0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2bd24ecb-d751-4afc-b00f-1c09ffcee8f0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2bd24ecb-d751-4afc-b00f-1c09ffcee8f0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        marketplace customer_id       review_id  product_id product_parent  \\\n",
       "0                US    50423057  R135Q3VZ4DQN5N  B00JWXFDMG      657335467   \n",
       "1                US    11262325  R2N0QQ6R4T7YRY  B00W5T1H9W       26030170   \n",
       "2                US    27541121  R3N5JE5Y4T6W5M  B00M2L6KFY      697845240   \n",
       "3                US     5350721  R2I150CX5IVY9Q  B0006SW2WU      569859289   \n",
       "4                US    24484424  R1RM9ICOOA9MQ3  B009YPDW70      332947422   \n",
       "...             ...         ...             ...         ...            ...   \n",
       "3042230          US    52895472   RVR5HEPUCU2C0  B00005RE3U      587330987   \n",
       "3042231          US    40225563   R7FC4HLPYQCBV  B00005OTBA      945322302   \n",
       "3042232          US    51016122  R1UD30PTI793U2  0930948246      698292720   \n",
       "3042233          US    43629114  R1DXZZ4QSXZLTP  B00005OTAJ      274507819   \n",
       "3042234          US    51769631   RV2EZ4SCOCQC2  B00005OTAD      249706161   \n",
       "\n",
       "                                             product_title product_category  \\\n",
       "0        Everbling Purple and Clear Briolette Drop Swar...          Jewelry   \n",
       "1        925 Sterling Silver Finish 6ct Simulated Diamo...          Jewelry   \n",
       "2        Sterling Silver Circle \"Friends Forever\" Infin...          Jewelry   \n",
       "3        Surgical Stainless Steel Domed 9mm Fishbone Ri...          Jewelry   \n",
       "4             Sterling Silver Family Pendant Necklace, 18\"          Jewelry   \n",
       "...                                                    ...              ...   \n",
       "3042230       Sterling Silver Toggle Bracelet, Round Charm          Jewelry   \n",
       "3042231  10K Yellow Gold &#46;01 ct&#46; Diamond Heart ...          Jewelry   \n",
       "3042232  Country & Blues Harmonica for the Absolute Beg...          Jewelry   \n",
       "3042233          14K Gold Diamond Cut Etched Hoop Earrings          Jewelry   \n",
       "3042234                    Floating Heart Pendant Necklace          Jewelry   \n",
       "\n",
       "        star_rating helpful_votes total_votes vine verified_purchase  \\\n",
       "0                 5             0           0    N                 Y   \n",
       "1                 5             0           0    N                 N   \n",
       "2                 5             0           0    N                 Y   \n",
       "3                 5             0           0    N                 Y   \n",
       "4                 5             0           0    N                 Y   \n",
       "...             ...           ...         ...  ...               ...   \n",
       "3042230           4             0           0    N                 N   \n",
       "3042231           4             6           7    N                 N   \n",
       "3042232           4             9           9    N                 N   \n",
       "3042233           5             8          10    N                 N   \n",
       "3042234           5            17          28    N                 N   \n",
       "\n",
       "                                           review_headline  \\\n",
       "0                                                Beauties!   \n",
       "1                                           Great product.   \n",
       "2        Exactly as pictured and my daughter's friend l...   \n",
       "3                                               Five Stars   \n",
       "4        ... a Mother's Day gift for my Mom and she lov...   \n",
       "...                                                    ...   \n",
       "3042230                                      nice bracelet   \n",
       "3042231                  beautiful heart for everyday wear   \n",
       "3042232                    Great for the Absolute Beginner   \n",
       "3042233                                           Dazzling   \n",
       "3042234                                     Touching Heart   \n",
       "\n",
       "                                               review_body review_date  \n",
       "0        so beautiful even tho clearly not high end ......  2015-08-31  \n",
       "1        Great product.. I got this set for my mother, ...  2015-08-31  \n",
       "2        Exactly as pictured and my daughter's friend l...  2015-08-31  \n",
       "3        Love it. Fits great. Super comfortable and nea...  2015-08-31  \n",
       "4        Got this as a Mother's Day gift for my Mom and...  2015-08-31  \n",
       "...                                                    ...         ...  \n",
       "3042230  It is nice looking and everything (it is sterl...  2001-11-25  \n",
       "3042231  my boyfriend bought me this last christmas, an...  2001-11-24  \n",
       "3042232  This is a great way to quickly start learning ...  2001-11-24  \n",
       "3042233  the 14kt gold earrings look remarkable...would...  2001-11-18  \n",
       "3042234  It will be a gift to my special friend. We kno...  2001-11-10  \n",
       "\n",
       "[3042235 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.tsv\", index_col = False, sep=\"\\\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDB53dpFF62T",
    "outputId": "8328f0ee-7b6a-418f-8ddd-404532889dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Xn5DbdKvOv_"
   },
   "source": [
    "## 1. Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fllyAypuf6ba",
    "outputId": "f5523b38-222a-4957-acc9-45b55658ef54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_body    0\n",
       "star_rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['review_body','star_rating']]\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 942
    },
    "id": "j3MNZk5YghrX",
    "outputId": "cfb82eed-efaa-4e9b-9426-d430cb7a496d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a051adc7-df55-408b-b919-7bda3b6a06f1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disappointed that this was sent out when you c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I returned them! They are really small, you ev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FELL APART BEFORE I EVEN WORE IT!!! SO FRAGILE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When I presented this charm I was informed tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deceiving because they don't tell u the earrin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>This ring is super pretty! The size I ordered ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>The stones in this are larger than they appear...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Well made.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Just what I needed.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>We bought this for my husbands mother as a bir...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a051adc7-df55-408b-b919-7bda3b6a06f1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a051adc7-df55-408b-b919-7bda3b6a06f1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a051adc7-df55-408b-b919-7bda3b6a06f1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                             review_body  star_rating\n",
       "0      Disappointed that this was sent out when you c...            1\n",
       "1      I returned them! They are really small, you ev...            1\n",
       "2      FELL APART BEFORE I EVEN WORE IT!!! SO FRAGILE...            1\n",
       "3      When I presented this charm I was informed tha...            1\n",
       "4      Deceiving because they don't tell u the earrin...            1\n",
       "...                                                  ...          ...\n",
       "99995  This ring is super pretty! The size I ordered ...            5\n",
       "99996  The stones in this are larger than they appear...            5\n",
       "99997                                         Well made.            5\n",
       "99998                                Just what I needed.            5\n",
       "99999  We bought this for my husbands mother as a bir...            5\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_data(df):\n",
    "    data = df[df['star_rating'] == '1'].sample(n=20000) # select 20000 first calss data that rating is 1\n",
    "    for i in range(2,6):\n",
    "        data1 = df[df['star_rating']== str(i)].sample(n=20000) # select data of class 2,3,4,5 by looping\n",
    "        data = data.append(data1, ignore_index=True)\n",
    "    return data\n",
    "  \n",
    "data =select_data(df)\n",
    "data['star_rating'] = data['star_rating'].apply(int) #change star_rating data to int type\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqN_mZu8G72C",
    "outputId": "f101378a-3cc2-4352-ccc1-0389ba3d12a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.72)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
      "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n"
     ]
    }
   ],
   "source": [
    "pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZX2uLvRIG3WD"
   },
   "outputs": [],
   "source": [
    "import contractions\n",
    "def word_lower(data):\n",
    "    data['review_body'] = data['review_body'].str.lower() # convert the all reviews data into the lower case\n",
    "    return data\n",
    "\n",
    "def remove_HTML_URL(text):\n",
    "    text = re.sub('<.*?>', ' ', text)\n",
    "    text = re.sub(\"https://\\S+|www\\.\\S+\", ' ', text) ## remove all html/url symbol \n",
    "    return text\n",
    "\n",
    "def remove_non_alphabetical(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]+', '',text) # remove all non-alphabetical character\n",
    "    return text\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    res = \" \".join(text.split()) # remove extra space\n",
    "    return res\n",
    "\n",
    "def perform_contractions(text): # perform contractions on the reviews\n",
    "    list1 = []\n",
    "    for word in text.split():\n",
    "        list1.append(contractions.fix(word))\n",
    "    return \" \".join(list1)\n",
    "\n",
    "data = word_lower(data)\n",
    "data['review_body'] = data['review_body'].apply(lambda x: perform_contractions(x))\n",
    "data['review_body'] = data['review_body'].apply(lambda x: remove_HTML_URL(x))\n",
    "data['review_body'] = data['review_body'].apply(lambda x: remove_non_alphabetical(x))\n",
    "data['review_body'] = data['review_body'].apply(lambda x: remove_extra_spaces(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vx3HxLUpuyxb"
   },
   "source": [
    "I did the basic data clean for the reivew data in order to decrease bad effect of the special character to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Etcyk-tgmck",
    "outputId": "4df43e36-fc1f-4d44-ec29-2bc387e0ca70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75220    the shipping took longer than expected but i s...\n",
       "48955    it is really cute and looks better than the pi...\n",
       "44966    the necklace pretty nice with pendant design b...\n",
       "13568    do not waste your money on this i was astonish...\n",
       "92727    i bought this as a friendship ring for a frien...\n",
       "                               ...                        \n",
       "6265     the idea and the actual content was nice but t...\n",
       "54886                     picture was nicer than in person\n",
       "76820    i chose this because i like two toned jewelry ...\n",
       "860      i bought this ring to use while at work and af...\n",
       "15795                        it the balls were way too big\n",
       "Name: review_body, Length: 80000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data['review_body']\n",
    "y = data['star_rating']\n",
    "x_train_data, x_test_data, y_train_data, y_test_data = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "x_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hbIhQ5ViPdg"
   },
   "source": [
    "## 2. Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hyjrtDEyxKg"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "google_model = api.load(\"word2vec-google-news-300\") #Load the pretrained “word2vec-google-news-300” Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYkhzBwg1Aos",
    "outputId": "001479d6-fcfe-4d47-9a03-11e8fb141e39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64546573"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_model.wv.similarity(w1 = 'nice', w2 = 'great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XViFsMut1P2U",
    "outputId": "9ec5c1f7-df56-46ba-a5c9-ac550aeeb48d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5958257"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_model.wv.similarity(w1 = 'picture', w2 = 'photo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uTIkvYMB1UN1",
    "outputId": "2a07ca52-8432-41c6-c64f-198e42b131d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33878717"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_model.wv.similarity(w1 = 'watch', w2 = 'look')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRPyltFr-F0M"
   },
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47gqRF6SRSik"
   },
   "outputs": [],
   "source": [
    "x_train_data = x_train_data.to_list()\n",
    "x_train_data_list = []\n",
    "for i in x_train_data:\n",
    "  list1 = []\n",
    "  for j in i.split():\n",
    "    list1.append(j)\n",
    "  x_train_data_list.append(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MctLYM_z8gDc"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "Word2Vec_model = Word2Vec(sentences = x_train_data_list, size = 300, window = 11, min_count=10) # create the word2vec model with 300 embedding size, 11 window size, and min count 10 word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2jHJE9T3OVe",
    "outputId": "eb63f9d7-85e3-40d2-d3fa-424689c76ea9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67641896"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word2Vec_model.wv.similarity(w1 = 'nice', w2 = 'great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fk-yQKv13UD0",
    "outputId": "54bb49c0-3fa5-45c4-d010-757e2226bbf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93262094"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word2Vec_model.wv.similarity(w1 = 'picture', w2 = 'photo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhPfnUPO3X6s",
    "outputId": "5fa26959-b559-411c-9e23-5c4809c954f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0027710078"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word2Vec_model.wv.similarity(w1 = 'watch', w2 = 'look')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRBLK-T9Vpyl"
   },
   "source": [
    "Pretrained word2vec-google-news-300 model: cosine similarity of word nice and great is 0.64546573, cosine similarity of word picture and photo is 0.5958257, cosine similarity of word watch and look 0.33878717.\n",
    "Myself Word2Vec model: cosine similarity of word nice and great is 0.67641896, cosine similarity of word picture and photo is 0.93262094, cosine similarity of word watch and look -0.0027710078.\n",
    "For the fist example, the result of two model are similar; for the second example, the result of myself Word2Vec model is much better than pretrained model; for the third example, the result of pretrained model is much better than myself Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSf1MOl_ccP1"
   },
   "source": [
    "### 3.Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8G3ealmeWl_"
   },
   "outputs": [],
   "source": [
    "x_train_vector_list = [] ## list to keep all vector of each word of train data after use word2vec model\n",
    "for i in range(len(x_train_data_list)):\n",
    "  list1 = np.zeros(300)\n",
    "  for word in x_train_data_list[i]: # iterate every word of a review\n",
    "    if word in google_model.wv.vocab: # check if word is in the model's vocabulary\n",
    "      list1 += google_model.wv[word] # sum all the vector \n",
    "    list1 = list1/len(x_train_data_list[i]) # count the averge vector of a review data\n",
    "  x_train_vector_list.append(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWOzu6fpHjzQ",
    "outputId": "56ee01f5-f0d7-42f1-e8ee-91b88d9ea963"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vector_list = np.array(x_train_vector_list) # convert the list to array\n",
    "x_train_vector_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txAe7ttT9O6G"
   },
   "outputs": [],
   "source": [
    "x_test_data = x_test_data.to_list() # convert test data to list\n",
    "x_test_data_list = []\n",
    "for i in x_test_data:\n",
    "  list1 = []\n",
    "  for j in i.split():\n",
    "    list1.append(j) # append every word of review\n",
    "  x_test_data_list.append(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEn4Z-MB9WvG"
   },
   "outputs": [],
   "source": [
    "x_test_vector_list = [] ## list to keep all vector of each word of test data after use word2vec model\n",
    "for i in range(len(x_test_data_list)):\n",
    "  list1 = np.zeros(300)\n",
    "  for word in x_test_data_list[i]:\n",
    "    if word in google_model.wv.vocab:\n",
    "      list1 += google_model.wv[word]\n",
    "    list1 = list1/len(x_test_data_list[i])\n",
    "  x_test_vector_list.append(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qx5U3Dv3-EVW",
    "outputId": "e9c1efff-d6ff-4f68-eac7-31b2a39b4f6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_vector_list = np.array(x_test_vector_list) # convert list to array\n",
    "x_test_vector_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQqVLJXCDNqz"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "Perceptron_model = Perceptron() \n",
    "Perceptron_model.fit(x_train_vector_list,y_train_data) # train the perceptron model\n",
    "y_predict_data = Perceptron_model.predict(x_test_vector_list) # predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EqSO7lILD9nE",
    "outputId": "84800ca4-0c6e-4262-f76e-46c13b83d11b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2591"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4']\n",
    "summary = classification_report(y_test_data, y_predict_data, target_names=target_names, output_dict = True)\n",
    "summary['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZVOom4-Ps9X"
   },
   "source": [
    "For the last homework, the accurary of Perceptron is 0.39035, and the accurary of Perceptron of this homework is 0.2591. Compare the result, the accuracy of TF-IDF feature is much better than the accuracy of pretrained Word2Vec features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5pDMnerUIu6"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM = SVC(kernel='linear', gamma='auto')\n",
    "SVM.fit(x_train_vector_list,y_train_data) # train the perceptron model\n",
    "SVM_y_predict_data = SVM.predict(x_test_vector_list) #predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrGnrobYUVEC",
    "outputId": "6e3cd1a1-ce57-4bd7-9679-91106b0b9425"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2578"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4']\n",
    "summary_SVM = classification_report(y_test_data, SVM_y_predict_data, target_names=target_names, output_dict = True)\n",
    "summary_SVM['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zm3r7XnVJOUv"
   },
   "source": [
    "For the last homework, the accurary of SVM is 0.5036, and the accurary of SVM of this homework is 0.2578. Compare the result, the accuracy of TF-IDF feature is much better than the accuracy of pretrained Word2Vec features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WB33ZRzb_n0Y"
   },
   "source": [
    "## 4. Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhg1EhrvXNis"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "MLP = Sequential() # ceate MLP model\n",
    "MLP.add(Dense(300,input_shape=(300,), activation='relu')) # input layer with 300 node \n",
    "MLP.add(Dense(50, activation='relu')) # first hidden layer with 50 node\n",
    "MLP.add(Dense(10, activation='relu')) # second hidden layer with 10 node\n",
    "MLP.add(Dense(5, activation='sigmoid')) # output layer with 5 node beacuse there are 5 class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UxmZVeeUY6Z"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x_train_tensor = tf.convert_to_tensor(x_train_vector_list) # convert x train data to tensor type\n",
    "x_test_tensor = tf.convert_to_tensor(x_test_vector_list) # convert x test data to tensor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYJbC3xDjskk",
    "outputId": "32a06bbe-a769-4218-8243-8210e67201c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "OHE_model = OneHotEncoder(handle_unknown='ignore') # apply one hot encoding\n",
    "OHE_y_train_data = OHE_model.fit_transform(np.array(y_train_data).reshape(-1,1)).toarray() # convert y train data to one hot coding\n",
    "OHE_y_train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kNRINiihLc5",
    "outputId": "9f551186-9103-4229-f568-91eb097cd221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "160/160 [==============================] - 3s 3ms/step - loss: 1.5595 - accuracy: 0.2722\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.5113 - accuracy: 0.3076\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.4926 - accuracy: 0.3195\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.4819 - accuracy: 0.3266\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.4730 - accuracy: 0.3319\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.4654 - accuracy: 0.3359\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.4590 - accuracy: 0.3386\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.4531 - accuracy: 0.3415\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.4486 - accuracy: 0.3455\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.4456 - accuracy: 0.3469\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.4380 - accuracy: 0.3524\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.4341 - accuracy: 0.3535\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.4316 - accuracy: 0.3555\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.4265 - accuracy: 0.3587\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.4259 - accuracy: 0.3600\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.4204 - accuracy: 0.3620\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.4171 - accuracy: 0.3645\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.4135 - accuracy: 0.3651\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.4114 - accuracy: 0.3659\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.4085 - accuracy: 0.3690\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.4058 - accuracy: 0.3688\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.4042 - accuracy: 0.3707\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.4011 - accuracy: 0.3726\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3987 - accuracy: 0.3746\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3959 - accuracy: 0.3754\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3935 - accuracy: 0.3770\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3900 - accuracy: 0.3790\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3904 - accuracy: 0.3774\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3873 - accuracy: 0.3798\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3841 - accuracy: 0.3806\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.3841 - accuracy: 0.3809\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3820 - accuracy: 0.3809\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.3780 - accuracy: 0.3849\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3761 - accuracy: 0.3856\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3756 - accuracy: 0.3866\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3719 - accuracy: 0.3890\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3718 - accuracy: 0.3872\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3676 - accuracy: 0.3903\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3667 - accuracy: 0.3921\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3643 - accuracy: 0.3897\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 1.3627 - accuracy: 0.3929\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3620 - accuracy: 0.3918\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.3583 - accuracy: 0.3956\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.3580 - accuracy: 0.3954\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 1.3567 - accuracy: 0.3962\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3569 - accuracy: 0.3943\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.3522 - accuracy: 0.3972\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3501 - accuracy: 0.4003\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3497 - accuracy: 0.3993\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.3480 - accuracy: 0.3985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f94e900e610>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy']) # compile the model\n",
    "\n",
    "MLP.fit(x_train_tensor, OHE_y_train_data, epochs=50, batch_size=500) # train MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEwsi7_Oo6B1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.math_ops import arg_max\n",
    "y_pre = MLP.predict(x_test_tensor) # predit y test data\n",
    "y_pre_list = []\n",
    "for item in y_pre:\n",
    "  y_pre_list.append(np.argmax(item,axis=0)+1) # select the class of predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B2opzz0wsoMH",
    "outputId": "182c8288-5377-4f04-87de-a128c4c285f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33795"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test_data, y_pre_list) # count the accuracy\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo5lohAJCLXW"
   },
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qInQU_zCKlw"
   },
   "outputs": [],
   "source": [
    "x_train_10vector_list = [] # create a list to keep the first 10 word of each review of train data\n",
    "x_train_data_list1 = x_train_data_list.copy()\n",
    "for i in range(len(x_train_data_list1)): # loop to iterate the review data\n",
    "  if len(x_train_data_list1[i]) >= 10: # if the review length is bigger than 10\n",
    "    x_train_data_list1[i] = x_train_data_list1[i][0:10] # select the first 10 word\n",
    "    list2 = []\n",
    "    for word in x_train_data_list1[i]: # loop to iterate each word\n",
    "      if word in google_model.wv.vocab: # check if word is in vocabulary\n",
    "        vec = google_model.wv[word].tolist() # get the vector of word\n",
    "        for item in vec:\n",
    "          list2.append(item) # add the word vector to list\n",
    "      else: # if word is not in vocablary\n",
    "        for k in range(300):\n",
    "          list2.append(0) # set the vector to 0 and add to list\n",
    "  else: # if review length is less than 10\n",
    "    list2 = []\n",
    "    num = 10 - len(x_train_data_list1[i]) # count the number of we needed \n",
    "    for word in x_train_data_list1[i]: # loop to iterate each word\n",
    "      if word in google_model.wv.vocab: # check if word is in vocabulary\n",
    "        vec = google_model.wv[word].tolist() # get the vector of word\n",
    "        for item in vec:\n",
    "          list2.append(item) # add the word vector to list\n",
    "      else: # if word is not in vocablary\n",
    "        for k in range(300):\n",
    "          list2.append(0) # set the vector to 0\n",
    "    for h in range(num):\n",
    "      for o in range(300): # set word vector to 0 and add it to list\n",
    "        list2.append(0)\n",
    "  x_train_10vector_list.append(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wDRrq6FFGtmq",
    "outputId": "fb416733-7203-470a-bc70-a663a65a9c7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 3000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_10vector_list = np.array(x_train_10vector_list) # convert list to array\n",
    "x_train_10vector_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJSalwelC1HX"
   },
   "outputs": [],
   "source": [
    "x_test_10vector_list = [] # create a list to keep the first 10 word of each review of test data\n",
    "x_test_data_list1 = x_test_data_list.copy()\n",
    "for i in range(len(x_test_data_list1)): # loop to iterate the review data\n",
    "  if len(x_test_data_list1[i]) >= 10: # if the review length is bigger than 10\n",
    "    x_test_data_list1[i] = x_test_data_list1[i][0:10] # select the first 10 word\n",
    "    list2 = []\n",
    "    for word in x_test_data_list1[i]: # loop to iterate each word\n",
    "      if word in google_model.wv.vocab: # check if word is in vocabulary\n",
    "        vec = google_model.wv[word].tolist() # get the vector of word\n",
    "        for item in vec:\n",
    "          list2.append(item) # add the word vector to list\n",
    "      else: # if word is not in vocablary\n",
    "        for k in range(300):\n",
    "          list2.append(0) # set the vector to 0 and add to list\n",
    "  else: # if review length is less than 10\n",
    "    list2 = []\n",
    "    num = 10 - len(x_test_data_list1[i]) # count the number of we needed \n",
    "    for word in x_test_data_list1[i]:  # loop to iterate each word\n",
    "      if word in google_model.wv.vocab: # check if word is in vocabulary\n",
    "        vec = google_model.wv[word].tolist()  # get the vector of word\n",
    "        for item in vec:\n",
    "          list2.append(item) # add the word vector to list\n",
    "      else: # if word is not in vocablary\n",
    "        for k in range(300):\n",
    "          list2.append(0) # set the vector to 0\n",
    "    for h in range(num):\n",
    "      for o in range(300): # set word vector to 0 and add it to list\n",
    "        list2.append(0)\n",
    "  x_test_10vector_list.append(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIOwvl5XHrbZ",
    "outputId": "9fee2a73-5b35-4f4b-f3cc-386af7c7ac3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 3000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_10vector_list = np.array(x_test_10vector_list) # convert list to list\n",
    "x_test_10vector_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZXVSo74tQJ5"
   },
   "outputs": [],
   "source": [
    "x_train_10vector_tensor = tf.convert_to_tensor(x_train_10vector_list) # convert train data to tensor type\n",
    "x_test_10vector_tensor = tf.convert_to_tensor(x_test_10vector_list)# convert test data to tensor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6Oe2GIOvH-H"
   },
   "outputs": [],
   "source": [
    "MLP2 = Sequential()\n",
    "MLP2.add(Dense(3000, input_shape=(3000,), activation='relu')) # input layer with 3000 node \n",
    "MLP2.add(Dense(50, activation='relu')) # first hidden layer with 50 node \n",
    "MLP2.add(Dense(10, activation='relu')) # second hidden layer with 10 node\n",
    "MLP2.add(Dense(5, activation='sigmoid')) # output layer with 5 node beacuse there are 5 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0t9rZwgxZLiY",
    "outputId": "8f508233-cc4d-44da-cd4a-f05d6905e237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 1.3881 - accuracy: 0.3713\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 1.2516 - accuracy: 0.4477\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 1.1284 - accuracy: 0.5143\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.9537 - accuracy: 0.6002\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.7408 - accuracy: 0.7034\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 2s 11ms/step - loss: 0.5354 - accuracy: 0.7945\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.3736 - accuracy: 0.8616\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.2684 - accuracy: 0.9018\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.2000 - accuracy: 0.9280\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1685 - accuracy: 0.9393\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1511 - accuracy: 0.9451\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1324 - accuracy: 0.9516\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1270 - accuracy: 0.9528\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1167 - accuracy: 0.9574\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1055 - accuracy: 0.9611\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1025 - accuracy: 0.9614\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.1071 - accuracy: 0.9596\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0971 - accuracy: 0.9631\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0995 - accuracy: 0.9630\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0909 - accuracy: 0.9650\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0820 - accuracy: 0.9691\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0774 - accuracy: 0.9706\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0783 - accuracy: 0.9701\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0860 - accuracy: 0.9675\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0847 - accuracy: 0.9681\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0862 - accuracy: 0.9678\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0816 - accuracy: 0.9685\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0765 - accuracy: 0.9706\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0716 - accuracy: 0.9719\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0770 - accuracy: 0.9698\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0753 - accuracy: 0.9702\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0742 - accuracy: 0.9710\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0705 - accuracy: 0.9725\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0607 - accuracy: 0.9753\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0661 - accuracy: 0.9729\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0707 - accuracy: 0.9716\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0732 - accuracy: 0.9714\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0679 - accuracy: 0.9733\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0618 - accuracy: 0.9750\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0620 - accuracy: 0.9753\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0670 - accuracy: 0.9734\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0653 - accuracy: 0.9743\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0643 - accuracy: 0.9744\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0693 - accuracy: 0.9721\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0632 - accuracy: 0.9749\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0608 - accuracy: 0.9755\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0584 - accuracy: 0.9763\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0544 - accuracy: 0.9778\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 0.0533 - accuracy: 0.9774\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0566 - accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f94e8bee9d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy']) # compile model\n",
    "MLP2.fit(x_train_10vector_tensor, OHE_y_train_data, epochs=50, batch_size=500) # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bwdJUAAtdHn",
    "outputId": "28865886-db3d-4726-a1d9-f4dd5b4d3797"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4027"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre_10vector = MLP2.predict(x_test_10vector_tensor) # predict the y test\n",
    "y_pre_10vector_list = []\n",
    "for item in y_pre_10vector:\n",
    "  y_pre_10vector_list.append(np.argmax(item,axis=0)+1) # select the class \n",
    "\n",
    "accuracy_10vector = accuracy_score(y_test_data, y_pre_10vector_list) # count the accuracy\n",
    "accuracy_10vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbgUUdmcYIKj"
   },
   "source": [
    "The accuracy of first model is 0.33795, and accuracy of the second model is 0.4023, which is much better than first model. Since the number of data is same, the model is same, and the hyperparameter is same for both model, but the input vector of second model 3000, and the first model only have 300. In this case, i can conclude that the number of word vector have a big effect to the model. The more vector data have, the accury will be higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUaXIce1IpoA"
   },
   "source": [
    "## 5. Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kTNJTbg7ubo"
   },
   "outputs": [],
   "source": [
    "x_train_20vector_list = [] # create a list to keep the first 20 word of each review of train data \n",
    "x_train_data_list2 = x_train_data_list.copy()\n",
    "for i in range(len(x_train_data_list2)): # iterate the data list\n",
    "  list1 = []\n",
    "  if len(x_train_data_list2[i]) >= 20: # check the length of review data\n",
    "    x_train_data_list2[i] = x_train_data_list2[i][0:20] # select first 20 word \n",
    "    for word in x_train_data_list2[i]:\n",
    "      if word in google_model.wv.vocab: # check if word is in vocabulary\n",
    "        vec = google_model.wv[word] # get the word vector\n",
    "        list1.append(vec) # add to list\n",
    "      else: # if word is not in vocabulary\n",
    "        list1.append(np.zeros(300)) # set 0 as vector and add to list\n",
    "  else:\n",
    "    num = 20 - len(x_train_data_list2[i]) # check the length \n",
    "    for word in x_train_data_list2[i]:\n",
    "      if word in google_model.wv.vocab: # check if word is in vocabulary\n",
    "        vec = google_model.wv[word] # get the word vector\n",
    "        list1.append(vec) # add to list\n",
    "      else: # if word is not in vocabulary\n",
    "        list1.append(np.zeros(300)) # set 0 as vector and add to list\n",
    "    for n in range(num): # add the less word to list \n",
    "      list1.append(np.zeros(300))\n",
    "  x_train_20vector_list.append(list1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKCR1Nvp8EpI",
    "outputId": "88395d27-4f4a-4164-cf25-f3484957d5aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 20, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_20vector_list = np.array(x_train_20vector_list) # convert to array\n",
    "x_train_20tensor = tf.convert_to_tensor(x_train_20vector_list) # convert the data type\n",
    "x_train_20vector_list.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2t9SvooJLiy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "RNN_model = Sequential() \n",
    "RNN_model.add(SimpleRNN(300, input_shape=(None, 300))) # create the RNN model\n",
    "RNN_model.add(Dense(20, activation='relu')) # hidden layer with 20 node\n",
    "RNN_model.add(Dense(5, activation='sigmoid')) # output layer with 5 node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8nm2kDziqCz",
    "outputId": "a9c61eab-9279-4d23-bf9e-32ba09f9e453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "160/160 [==============================] - 3s 13ms/step - loss: 1.3761 - accuracy: 0.3780\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 1.2670 - accuracy: 0.4415\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 1.2404 - accuracy: 0.4570\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.2122 - accuracy: 0.4672\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.1906 - accuracy: 0.4782\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 1.1701 - accuracy: 0.4902\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 1.1529 - accuracy: 0.4967\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 1.1396 - accuracy: 0.5029\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 1.1182 - accuracy: 0.5167\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 1.1058 - accuracy: 0.5225\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 1.0890 - accuracy: 0.5295\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 1.0747 - accuracy: 0.5375\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.0547 - accuracy: 0.5453\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 1.0435 - accuracy: 0.5526\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 1.0261 - accuracy: 0.5616\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 1.0088 - accuracy: 0.5704\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.9946 - accuracy: 0.5775\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.9707 - accuracy: 0.5879\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.9527 - accuracy: 0.5965\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.9385 - accuracy: 0.6041\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.9197 - accuracy: 0.6153\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.9006 - accuracy: 0.6225\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.8811 - accuracy: 0.6327\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 0.8657 - accuracy: 0.6387\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.8458 - accuracy: 0.6471\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.8292 - accuracy: 0.6560\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.8132 - accuracy: 0.6620\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.7954 - accuracy: 0.6701\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.7781 - accuracy: 0.6799\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.7580 - accuracy: 0.6890\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.7473 - accuracy: 0.6944\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.7274 - accuracy: 0.7034\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.7118 - accuracy: 0.7095\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.7003 - accuracy: 0.7154\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.6782 - accuracy: 0.7244\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.6698 - accuracy: 0.7278\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.6566 - accuracy: 0.7342\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.6431 - accuracy: 0.7422\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.6272 - accuracy: 0.7478\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.6142 - accuracy: 0.7534\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.6112 - accuracy: 0.7538\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.5890 - accuracy: 0.7641\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.5828 - accuracy: 0.7673\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.5758 - accuracy: 0.7713\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.5578 - accuracy: 0.7758\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.5531 - accuracy: 0.7814\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.5466 - accuracy: 0.7843\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.5322 - accuracy: 0.7890\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.5330 - accuracy: 0.7880\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.5139 - accuracy: 0.7970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f94e8acffd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "RNN_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])# compile model\n",
    "\n",
    "RNN_model.fit(x_train_20vector_list, OHE_y_train_data, epochs=50, batch_size=500) # train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmclRlg4S6C_"
   },
   "outputs": [],
   "source": [
    "x_test_20vector_list = [] # create a list to keep the first 20 word of each review of test data \n",
    "x_test_data_list2 = x_test_data_list.copy()\n",
    "for i in range(len(x_test_data_list2)): # iterate the data list\n",
    "  list1 = []\n",
    "  if len(x_test_data_list2[i]) >= 20: # check the length of review data \n",
    "    x_test_data_list2[i] = x_test_data_list2[i][0:20] # select first 20 word\n",
    "    for word in x_test_data_list2[i]:\n",
    "      if word in google_model.wv.vocab: # check if word is in vocabulary\n",
    "        vec = google_model.wv[word] # get the wor vector\n",
    "        list1.append(vec)\n",
    "      else: # if word is not in vocabulary\n",
    "        list1.append(np.zeros(300)) # set 0 as word vector\n",
    "  else:\n",
    "    num = 20 - len(x_test_data_list2[i]) # check the length \n",
    "    for word in x_test_data_list2[i]:\n",
    "      if word in google_model.wv.vocab: # check if word is in vocabulary\n",
    "        vec = google_model.wv[word] # get the wor vector\n",
    "        list1.append(vec)\n",
    "      else: # if word is not in vocabulary\n",
    "        list1.append(np.zeros(300)) # set 0 as word vector\n",
    "    for n in range(num):\n",
    "      list1.append(np.zeros(300)) # add the less word vector\n",
    "  x_test_20vector_list.append(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0v8VwRHuZjgk",
    "outputId": "06a68e7b-e5c7-48fd-a87c-2f05fe86a878"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42155"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_20tensor = tf.convert_to_tensor(x_test_20vector_list) # convert the data to tensor type \n",
    "y_pre_20vector = RNN_model.predict(x_test_20tensor) # predict the y test\n",
    "y_pre_20vector_list = []\n",
    "for item in y_pre_20vector:\n",
    "  y_pre_20vector_list.append(np.argmax(item,axis=0)+1) # select the class result\n",
    "\n",
    "accuracy_20vector = accuracy_score(y_test_data, y_pre_20vector_list) # get the accuracy\n",
    "accuracy_20vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJUVMozQcujN"
   },
   "source": [
    "##(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MGQ4IZJHcw7N",
    "outputId": "08afa21f-c51f-411e-d56c-c811172aa313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "160/160 [==============================] - 6s 14ms/step - loss: 1.3492 - accuracy: 0.3904\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.2265 - accuracy: 0.4595\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.1802 - accuracy: 0.4812\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.1563 - accuracy: 0.4905\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.1279 - accuracy: 0.5045\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.1079 - accuracy: 0.5113\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.0903 - accuracy: 0.5207\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.0744 - accuracy: 0.5271\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.0542 - accuracy: 0.5375\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.0315 - accuracy: 0.5489\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 1.0135 - accuracy: 0.5569\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.9896 - accuracy: 0.5682\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.9637 - accuracy: 0.5816\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.9326 - accuracy: 0.5957\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.8978 - accuracy: 0.6139\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.8551 - accuracy: 0.6342\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.8125 - accuracy: 0.6540\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.7600 - accuracy: 0.6806\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.7033 - accuracy: 0.7093\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.6340 - accuracy: 0.7384\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.5746 - accuracy: 0.7665\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.5049 - accuracy: 0.7982\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.4415 - accuracy: 0.8269\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.3792 - accuracy: 0.8542\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.3230 - accuracy: 0.8771\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.2755 - accuracy: 0.8965\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.2395 - accuracy: 0.9106\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.2063 - accuracy: 0.9237\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.1868 - accuracy: 0.9319\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.1624 - accuracy: 0.9415\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.1472 - accuracy: 0.9476\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.1354 - accuracy: 0.9510\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.1243 - accuracy: 0.9550\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.1199 - accuracy: 0.9566\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.1286 - accuracy: 0.9531\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.1078 - accuracy: 0.9612\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0969 - accuracy: 0.9648\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0898 - accuracy: 0.9675\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0849 - accuracy: 0.9687\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0919 - accuracy: 0.9665\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0966 - accuracy: 0.9643\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0989 - accuracy: 0.9640\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0945 - accuracy: 0.9656\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0778 - accuracy: 0.9720\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0694 - accuracy: 0.9743\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0617 - accuracy: 0.9770\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0645 - accuracy: 0.9756\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.1004 - accuracy: 0.9635\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.1060 - accuracy: 0.9611\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0905 - accuracy: 0.9660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f94e85c6c10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "RNN_model1 = Sequential() \n",
    "RNN_model1.add(GRU(300, input_shape=(None, 300))) # creat the GRU cell\n",
    "RNN_model1.add(Dense(20, activation='relu')) # hidden layer with 20 node\n",
    "RNN_model1.add(Dense(5, activation='sigmoid')) # output layer with 5 node\n",
    "\n",
    "RNN_model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "RNN_model1.fit(x_train_20vector_list, OHE_y_train_data, epochs=50, batch_size=500) # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0OIWBx3gYhB",
    "outputId": "baa21c9b-3bc1-4d90-c2dd-3508fece3d39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.466"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre_20vector1 = RNN_model1.predict(x_test_20tensor) # predict the y test\n",
    "y_pre_20vector_list1 = []\n",
    "for item in y_pre_20vector1:\n",
    "  y_pre_20vector_list1.append(np.argmax(item,axis=0)+1) # select the result\n",
    "\n",
    "accuracy_20vector1 = accuracy_score(y_test_data, y_pre_20vector_list1) # get the accuracy\n",
    "accuracy_20vector1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEpEv6JWlatQ"
   },
   "source": [
    "The accuracy of first model is 0.42155, and the accuracy of second model is 0.466, whcih is better than first model. Since number of input data and hyperparmeter are same for both model, we can say gated recurrent unit cell could make model better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyPjzE1YnZ81"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
